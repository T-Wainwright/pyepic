{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyepic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pyepic.EPICClient(\"TOKEN HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = \"~/my_data/\"\n",
    "remote_folder = \"epic://my_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync the local data to remote data, this will copy any new or updated files to EPIC\n",
    "# data_callback method used for monitoring the sync, uploaded will be true if the file has been copied\n",
    "# false if not.\n",
    "\n",
    "def data_callback(from_name, to_name, uploaded):\n",
    "    if uploaded:\n",
    "        print(f\"Copied {from_name} to {to_name}\")\n",
    "    else:\n",
    "        print(f\"Did not copy {from_name} to {to_name}\")\n",
    "\n",
    "client.data.sync(local_data, remote_folder, dryrun=False, callback=data_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, check we are using the right version of zcfd\n",
    "apps = client.catalog.list_applications(product_name=\"zcfd\")\n",
    "for app in apps:\n",
    "    for version in app.versions:\n",
    "        print(f\"ID={version.id} {app.product.name}({version.version}). Available on queues {version.queue_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the zcfd version we will use\n",
    "zcfd_application_id = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, check the details of the queue we want to use\n",
    "clusters = client.catalog.list_clusters(application_id=zcfd_application_id)\n",
    "\n",
    "for cluster in clusters:\n",
    "    print(f\"ID = {cluster.id}, Name = {cluster.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the cluster we will use\n",
    "cluster_id = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and submit a series of 10 zcfd jobs, \n",
    "# each run in the same folder on the same mesh but with different control files\n",
    "# 24 partitions per job\n",
    "from pyepic.applications.zcfd import ZCFDJob\n",
    "\n",
    "job_array = []\n",
    "\n",
    "for job_id in range(0, 3):\n",
    "    # Create the jobs\n",
    "    job_obj =  ZCFDJob(zcfd_application_id,\n",
    "                           f\"job_name_{job_id}\",\n",
    "                           \"epic://my_data/\",\n",
    "                           f\"control_file_{job_id}.py\",\n",
    "                           \"mesh.h5\",\n",
    "                           cycles=1000,\n",
    "                           restart=False,\n",
    "                           partitions=24)\n",
    "    \n",
    "    # Submit the jobs to the selected cluster\n",
    "    job_spec = job_obj.get_job_create_spec(cluster_id)\n",
    "    \n",
    "    # Submit the job and store the returned job object for future use\n",
    "    job_array.append(client.job.submit(job_spec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple monitor to check the jobs every 5 mins\n",
    "finished = 0 \n",
    "while finished <= 3:\n",
    "    for job in job_array:\n",
    "        job_details = client.job.get_details(job[0].id)\n",
    "        print(f\"Job ID: {job_details.id}, Status: {job_details.status}, Finished: {job_details.finished}\")\n",
    "        if job_details.finished:\n",
    "            finished += 1\n",
    "    time.sleep(60 * 5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the contents of a log file\n",
    "import io\n",
    "\n",
    "# Create a new BytesIO object\n",
    "log_file_0 = io.BytesIO()\n",
    "\n",
    "# Download contents of epic file into log_file_0\n",
    "client.data.download_file(\"epic://my_data/control_file_0.log\", log_file_0)\n",
    "\n",
    "# Do something with the data in memory\n",
    "log_file_0.seek(0)\n",
    "print(log_file_0.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-wings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
